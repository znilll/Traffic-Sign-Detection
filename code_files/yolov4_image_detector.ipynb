{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import time\n",
    "from keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform histogram equalization on the randomly selected image\n",
    "def equalize(img):\n",
    "  img = cv2.equalizeHist(img)\n",
    "  return img\n",
    "\n",
    "# Convert the randomly selected image to grayscale\n",
    "def grayscale(img):\n",
    "  img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "  return img\n",
    "\n",
    "# Perform grayscale conversion, histogram equalization and normalization on the whole dataset\n",
    "def preprocessing(img):\n",
    "  img = grayscale(img)\n",
    "  img = equalize(img)\n",
    "  img = img/255\n",
    "  return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model('../CNN_model/cnn_classifier.keras')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load weights\n",
    "path_to_weights = '../yolov4_model/yolov4_tsb_train_best.weights'\n",
    "# Load configuration file\n",
    "path_to_cfg = '../yolov4_model/yolov4_tsb_test.cfg'\n",
    "\n",
    "# Load weights and configuration file into the network\n",
    "network = cv2.dnn.readNetFromDarknet(path_to_cfg, path_to_weights)\n",
    "\n",
    "# To use with GPU\n",
    "network.setPreferableBackend(cv2.dnn.DNN_BACKEND_OPENCV) #OPENCV\n",
    "network.setPreferableTarget(cv2.dnn.DNN_TARGET_OPENCL_FP16) #OPENCL_FP16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get names of all YOLO v4 layers\n",
    "layers_all = network.getLayerNames()\n",
    "\n",
    "# Get only detection layers\n",
    "output_layers = network.getUnconnectedOutLayers()\n",
    "layers_names_output = [layers_all[i - 1] for i in output_layers]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    ClassId                                           SignName\n",
      "0         0                               Speed limit (20km/h)\n",
      "1         1                               Speed limit (30km/h)\n",
      "2         2                               Speed limit (50km/h)\n",
      "3         3                               Speed limit (60km/h)\n",
      "4         4                               Speed limit (70km/h)\n",
      "5         5                               Speed limit (80km/h)\n",
      "6         6                        End of speed limit (80km/h)\n",
      "7         7                              Speed limit (100km/h)\n",
      "8         8                              Speed limit (120km/h)\n",
      "9         9                                         No passing\n",
      "10       10       No passing for vechiles over 3.5 metric tons\n",
      "11       11              Right-of-way at the next intersection\n",
      "12       12                                      Priority road\n",
      "13       13                                              Yield\n",
      "14       14                                               Stop\n",
      "15       15                                        No vechiles\n",
      "16       16           Vechiles over 3.5 metric tons prohibited\n",
      "17       17                                           No entry\n",
      "18       18                                    General caution\n",
      "19       19                        Dangerous curve to the left\n",
      "20       20                       Dangerous curve to the right\n",
      "21       21                                       Double curve\n",
      "22       22                                         Bumpy road\n",
      "23       23                                      Slippery road\n",
      "24       24                          Road narrows on the right\n",
      "25       25                                          Road work\n",
      "26       26                                    Traffic signals\n",
      "27       27                                        Pedestrians\n",
      "28       28                                  Children crossing\n",
      "29       29                                  Bicycles crossing\n",
      "30       30                                 Beware of ice/snow\n",
      "31       31                              Wild animals crossing\n",
      "32       32                End of all speed and passing limits\n",
      "33       33                                   Turn right ahead\n",
      "34       34                                    Turn left ahead\n",
      "35       35                                         Ahead only\n",
      "36       36                               Go straight or right\n",
      "37       37                                Go straight or left\n",
      "38       38                                         Keep right\n",
      "39       39                                          Keep left\n",
      "40       40                               Roundabout mandatory\n",
      "41       41                                  End of no passing\n",
      "42       42  End of no passing by vechiles over 3.5 metric ...\n"
     ]
    }
   ],
   "source": [
    "# Load file with the names of traffic signs\n",
    "\n",
    "labels = pd.read_csv('../data/signnames.csv')\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimum probability to eliminate weak detections\n",
    "\n",
    "probability_minimum = 0.6\n",
    "\n",
    "# Set threshold to filter weak bounding boxes by non-maximum suppression\n",
    "threshold = 0.4\n",
    "\n",
    "# Generate colours for bounding boxes\n",
    "colours = np.random.randint(0, 255, size=(len(labels), 3), dtype='uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set default size of plots\n",
    "plt.rcParams['figure.figsize'] = (3, 3)\n",
    "\n",
    "\n",
    "# Variable for counting total amount of frames\n",
    "f = 0\n",
    "\n",
    "# Variable for counting total processing time\n",
    "t = 0\n",
    "\n",
    "# Path to the directory containing photos\n",
    "photos_directory = '../data/img'\n",
    "\n",
    "# Iterate through photos in the directory\n",
    "for photo_filename in os.listdir(photos_directory):\n",
    "    # Construct the full path to the photo\n",
    "    photo_path = os.path.join(photos_directory, photo_filename)\n",
    "\n",
    "    # Read the photo\n",
    "    frame = cv2.imread(photo_path)\n",
    "\n",
    "    # Get spatial dimensions of the frame for the first time\n",
    "    h, w = frame.shape[:2]\n",
    "\n",
    "    # Blob from the current frame\n",
    "    blob = cv2.dnn.blobFromImage(frame, 1 / 255.0, (800, 800), swapRB=True, crop=False)\n",
    "\n",
    "    # Forward pass with blob through output layers\n",
    "    network.setInput(blob)\n",
    "    start = time.time()\n",
    "    output_from_network = network.forward(layers_names_output)\n",
    "    end = time.time()\n",
    "\n",
    "    # Increase counters\n",
    "    f += 1\n",
    "    t += end - start\n",
    "\n",
    "    # Lists for detected bounding boxes, confidences, and class numbers\n",
    "    bounding_boxes = []\n",
    "    confidences = []\n",
    "    class_numbers = []\n",
    "\n",
    "    # Go through all output layers after feed forward pass\n",
    "    for result in output_from_network:\n",
    "        # Go through all detections from the current output layer\n",
    "        for detected_objects in result:\n",
    "            # Get 80 classes probabilities for the current detected object\n",
    "            scores = detected_objects[5:]\n",
    "            # Get the index of the class with the maximum value of probability\n",
    "            class_current = np.argmax(scores)\n",
    "            # Get the value of probability for the defined class\n",
    "            confidence_current = scores[class_current]\n",
    "\n",
    "            # Eliminate weak predictions by minimum probability\n",
    "            if confidence_current > probability_minimum:\n",
    "                # Scale bounding box coordinates to the initial frame size\n",
    "                box_current = detected_objects[0:4] * np.array([w, h, w, h])\n",
    "\n",
    "                # Get top-left corner coordinates\n",
    "                x_center, y_center, box_width, box_height = box_current\n",
    "                x_min = int(x_center - (box_width / 2))\n",
    "                y_min = int(y_center - (box_height / 2))\n",
    "\n",
    "                # Add results into prepared lists\n",
    "                bounding_boxes.append([x_min, y_min, int(box_width), int(box_height)])\n",
    "                confidences.append(float(confidence_current))\n",
    "                class_numbers.append(class_current)\n",
    "\n",
    "    # Implement non-maximum suppression of given bounding boxes\n",
    "    results = cv2.dnn.NMSBoxes(bounding_boxes, confidences, probability_minimum, threshold)\n",
    "\n",
    "    # Check if there is any detected object left\n",
    "    if len(results) > 0:\n",
    "        # Go through indexes of results\n",
    "        for i in results.flatten():\n",
    "            # Bounding box coordinates (width and height)\n",
    "            x_min, y_min = bounding_boxes[i][0], bounding_boxes[i][1]\n",
    "            box_width, box_height = bounding_boxes[i][2], bounding_boxes[i][3]\n",
    "\n",
    "            # Cut fragment with a traffic sign\n",
    "            c_ts = frame[y_min:y_min+int(box_height), x_min:x_min+int(box_width), :]\n",
    "\n",
    "            if c_ts.shape[:1] == (0,) or c_ts.shape[1:2] == (0,):\n",
    "                pass\n",
    "            else:\n",
    "                # Preprocess cut out fragments\n",
    "                c_ts = np.asarray(c_ts)\n",
    "                c_ts = cv2.resize(c_ts, (32, 32))\n",
    "                c_ts = preprocessing(c_ts)\n",
    "                c_ts = c_ts.reshape(1, 32, 32, 1)\n",
    "\n",
    "                # Feed to the Classification model to get predicted label among 43 classes\n",
    "                scores = best_model.predict(c_ts)\n",
    "\n",
    "                # Get only class with max confidence\n",
    "                prediction = np.argmax(scores)\n",
    "\n",
    "                # Color for the current bounding box\n",
    "                color_box_current = colours[class_numbers[i]].tolist()\n",
    "\n",
    "                # Draw bounding box on the original current frame\n",
    "                cv2.rectangle(frame, (x_min, y_min),\n",
    "                              (x_min + box_width, y_min + box_height),\n",
    "                              color_box_current, 2)\n",
    "\n",
    "                                # Prepare text with label and confidence for the current bounding box\n",
    "                text_box_current = '{}: {:.4f}'.format(labels['SignName'][prediction], confidences[i])\n",
    "\n",
    "                # Put text with label and confidence on the original image\n",
    "                cv2.putText(frame, text_box_current, (x_min, y_min - 5),\n",
    "                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, color_box_current, 2)\n",
    "        # Specify the output filename based on the input photo filename\n",
    "        output_filename = f\"processed_{os.path.splitext(photo_filename)[0]}.jpg\"\n",
    "\n",
    "        output_path = \"../results/images\"\n",
    "        # Save the processed frame to the output directory\n",
    "        cv2.imwrite(os.path.join(output_path, output_filename), frame)\n",
    "\n",
    "        # Wait for a key event\n",
    "        cv2.waitKey(0)\n",
    "\n",
    "# Close all windows after processing all images\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nilenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
